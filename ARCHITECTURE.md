# Arquitetura do Sistema Distribu√≠do - Mutir√µes# Arquitetura do Sistema - Mutir√µes



## üìä Vis√£o Geral## üìä Vis√£o Geral



Este projeto implementa uma **arquitetura distribu√≠da** com m√∫ltiplas r√©plicas, load balancing, banco de dados compartilhado e processamento ass√≠ncrono escal√°vel.Este projeto implementa uma **arquitetura monol√≠tica moderna** com processamento ass√≠ncrono, seguindo boas pr√°ticas de desenvolvimento e containeriza√ß√£o.



### Classifica√ß√£o da Arquitetura### Classifica√ß√£o da Arquitetura



- ‚úÖ **Sistema Distribu√≠do** - M√∫ltiplas r√©plicas do backend com load balancing- ‚úÖ **Monolito Modular** - Backend √∫nico com apps Django organizados

- ‚úÖ **Escalabilidade Horizontal** - Possibilidade de adicionar mais r√©plicas sob demanda- ‚úÖ **Processamento Ass√≠ncrono** - Celery para tarefas em background

- ‚úÖ **Processamento Ass√≠ncrono Distribu√≠do** - M√∫ltiplos Celery workers- ‚úÖ **Containerizado** - Docker Compose para orquestra√ß√£o

- ‚úÖ **Containerizado** - Docker Compose para orquestra√ß√£o- ‚úÖ **Separa√ß√£o Frontend/Backend** - Next.js (frontend) + Django (backend)

- ‚úÖ **Separa√ß√£o Frontend/Backend** - Next.js (frontend) + Django (backend)

### Stack Tecnol√≥gica

### Stack Tecnol√≥gica

**Backend:**

**Backend:**- Django 4.2.7 + Django REST Framework 3.14.0

- Django 4.2.7 + Django REST Framework 3.14.0- Python 3.11

- Python 3.11- JWT Authentication (djangorestframework-simplejwt)

- JWT Authentication (djangorestframework-simplejwt)- Celery 5.3.4 para tasks ass√≠ncronas

- Celery 5.3.4 para tasks ass√≠ncronas (2 workers)- Redis 7 como message broker

- Redis 7 como message broker e cache- SQLite (dev) / PostgreSQL (prod)

- PostgreSQL 15 (banco de dados relacional compartilhado)

- Gunicorn (WSGI server - 4 workers por r√©plica)**Frontend:**

- Next.js 15.5.4 (React 19)

**Load Balancer:**- TypeScript 5

- Nginx - distribui√ß√£o de carga entre r√©plicas- Tailwind CSS 3.4.18

- Rate limiting e prote√ß√£o contra DDoS

- Cache de arquivos est√°ticos**Infraestrutura:**

- Docker & Docker Compose

**Frontend:**- Gunicorn (WSGI server para produ√ß√£o)

- Next.js 15.5.4 (React 19)

- TypeScript 5## üèóÔ∏è Arquitetura de Componentes

- Tailwind CSS 3.4.18

```

**Infraestrutura:**‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

- Docker & Docker Compose‚îÇ                                                     ‚îÇ

- 8 containers principais‚îÇ  Frontend (Next.js)                                 ‚îÇ

- Volumes compartilhados para persist√™ncia‚îÇ  - React Components                                 ‚îÇ

‚îÇ  - Client-side routing                              ‚îÇ

## üèóÔ∏è Arquitetura de Componentes‚îÇ  - API client                                       ‚îÇ

‚îÇ                                                     ‚îÇ

```‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                           Internet/Usu√°rios                   ‚îÇ HTTP/REST

                                  ‚Üì                   ‚Üì

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

                    ‚îÇ   Nginx Load Balancer   ‚îÇ‚îÇ                                                     ‚îÇ

                    ‚îÇ   - Rate Limiting       ‚îÇ‚îÇ  Backend Django (Monolito)                          ‚îÇ

                    ‚îÇ   - Health Checks       ‚îÇ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ

                    ‚îÇ   - SSL/TLS Ready       ‚îÇ‚îÇ  ‚îÇ  Apps Django:                            ‚îÇ       ‚îÇ

                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ  ‚îÇ  - events/ (CRUD eventos, participantes) ‚îÇ       ‚îÇ

                                ‚îÇ‚îÇ  ‚îÇ  - users/ (Autentica√ß√£o, perfil)         ‚îÇ       ‚îÇ

                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ

                 ‚Üì              ‚Üì              ‚Üì‚îÇ                                                     ‚îÇ

          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ  APIs REST:                                         ‚îÇ

          ‚îÇ Backend1 ‚îÇ   ‚îÇ Backend2 ‚îÇ   ‚îÇ Backend3 ‚îÇ‚îÇ  - /api/events/                                     ‚îÇ

          ‚îÇ Django   ‚îÇ   ‚îÇ Django   ‚îÇ   ‚îÇ Django   ‚îÇ‚îÇ  - /api/users/                                      ‚îÇ

          ‚îÇ Gunicorn ‚îÇ   ‚îÇ Gunicorn ‚îÇ   ‚îÇ Gunicorn ‚îÇ‚îÇ  - /api/token/ (JWT)                                ‚îÇ

          ‚îÇ (4 work) ‚îÇ   ‚îÇ (4 work) ‚îÇ   ‚îÇ (4 work) ‚îÇ‚îÇ                                                     ‚îÇ

          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

               ‚îÇ              ‚îÇ              ‚îÇ         ‚îÇ                    ‚îÇ

               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚Üì                    ‚Üì

                              ‚Üì    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ SQLite ‚îÇ          ‚îÇ  Redis   ‚îÇ

                    ‚îÇ   PostgreSQL 15  ‚îÇ    ‚îÇ   /    ‚îÇ          ‚îÇ (broker) ‚îÇ

                    ‚îÇ   - Shared DB    ‚îÇ    ‚îÇPostgres‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                    ‚îÇ   - Persistent   ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ

                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                              ‚Üì

                              ‚Üì                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ  Celery Workers     ‚îÇ

               ‚Üì                             ‚Üì                    ‚îÇ  - Email tasks      ‚îÇ

        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ  - Cleanup tasks    ‚îÇ

        ‚îÇ Redis Cache ‚îÇ              ‚îÇ Redis Broker‚îÇ                    ‚îÇ  - Report tasks     ‚îÇ

        ‚îÇ - Sessions  ‚îÇ              ‚îÇ - Celery    ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

        ‚îÇ - API Cache ‚îÇ              ‚îÇ - Tasks     ‚îÇ                              ‚Üë

        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê

                                            ‚îÇ                    ‚îÇ  Celery Beat      ‚îÇ

                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ  (Scheduler)      ‚îÇ

                              ‚Üì                           ‚Üì                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê```

                    ‚îÇ Celery Worker 1  ‚îÇ      ‚îÇ Celery Worker 2  ‚îÇ

                    ‚îÇ - 4 concurrent   ‚îÇ      ‚îÇ - 4 concurrent   ‚îÇ## üì¶ Estrutura de Containers (Docker Compose)

                    ‚îÇ - Email tasks    ‚îÇ      ‚îÇ - Email tasks    ‚îÇ

                    ‚îÇ - Reports        ‚îÇ      ‚îÇ - Reports        ‚îÇ### Containers Ativos

                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                              ‚Üë| Container | Descri√ß√£o | Porta | Papel |

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê|-----------|-----------|-------|-------|

                    ‚îÇ   Celery Beat     ‚îÇ| `mutiroes-backend` | Django API | 8000 | Servidor principal da API REST |

                    ‚îÇ   - Scheduler     ‚îÇ| `mutiroes-redis` | Redis 7 | 6379 | Message broker para Celery |

                    ‚îÇ   - Periodic Tasks‚îÇ| `mutiroes-celery-worker` | Celery Worker | - | Processa tasks ass√≠ncronas |

                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò| `mutiroes-celery-beat` | Celery Beat | - | Agenda tasks peri√≥dicas |

```

### Volumes Persistentes

## üì¶ Estrutura de Containers

- `redis_data` - Dados do Redis (filas, cache)

### Containers Ativos (8 total)- `backend_media` - Arquivos de m√≠dia (fotos de eventos, avatares)

- `backend_static` - Arquivos est√°ticos (CSS, JS, imagens)

| Container | Descri√ß√£o | Porta | R√©plicas | Recursos |

|-----------|-----------|-------|----------|----------|## üîÑ Fluxo de Dados

| `mutiroes-nginx` | Load Balancer | 80 | 1 | Distribui entre 3 backends |

| `mutiroes-backend1` | Django API Replica 1 | - | 1 | 4 Gunicorn workers |### 1. Requisi√ß√£o S√≠ncrona (CRUD)

| `mutiroes-backend2` | Django API Replica 2 | - | 1 | 4 Gunicorn workers |

| `mutiroes-backend3` | Django API Replica 3 | - | 1 | 4 Gunicorn workers |```

| `mutiroes-postgres` | PostgreSQL 15 | 5432 | 1 | Database compartilhado |Usuario ‚Üí Frontend ‚Üí API Backend ‚Üí Database ‚Üí Response

| `mutiroes-redis` | Redis 7 | 6379 | 1 | Broker + Cache |```

| `mutiroes-celery-worker1` | Celery Worker 1 | - | 1 | 4 concurrent tasks |

| `mutiroes-celery-worker2` | Celery Worker 2 | - | 1 | 4 concurrent tasks |**Exemplo:** Listar eventos, criar evento, fazer check-in

| `mutiroes-celery-beat` | Celery Scheduler | - | 1 | Periodic tasks |

### 2. Processamento Ass√≠ncrono

**Total de workers simult√¢neos:**

- Backend: 3 r√©plicas √ó 4 Gunicorn workers = **12 workers HTTP**```

- Celery: 2 workers √ó 4 concurrency = **8 workers de tasks**API Backend ‚Üí Redis (enfileira) ‚Üí Celery Worker ‚Üí Executa task

```

### Volumes Compartilhados

**Exemplo:** Enviar email de boas-vindas ap√≥s registro

- `postgres_data` - Dados do PostgreSQL (persistente)

- `redis_data` - Dados do Redis (filas, cache)### 3. Tasks Peri√≥dicas

- `backend_media` - Arquivos de m√≠dia compartilhados entre backends

- `backend_static` - Arquivos est√°ticos compartilhados```

Celery Beat ‚Üí Agenda task ‚Üí Redis ‚Üí Celery Worker ‚Üí Executa

## üîÑ Fluxo de Requisi√ß√µes```



### 1. Requisi√ß√£o HTTP (Load Balanced)**Exemplo:** Limpeza de eventos expirados (diariamente √†s 2h)



```## üéØ Apps Django (M√≥dulos)

Usuario ‚Üí Nginx Load Balancer ‚Üí [Backend1 | Backend2 | Backend3] ‚Üí PostgreSQL ‚Üí Response

                ‚Üì### `events/` - Gest√£o de Eventos

        (least_conn algorithm)

        Escolhe backend com menos conex√µes ativas**Models:**

```- `EventCategory` - Categorias (Limpeza, Plantio, Monitoramento, Educa√ß√£o)

- `Event` - Evento principal com localiza√ß√£o, datas, capacidade

**Caracter√≠sticas:**- `EventParticipant` - Participantes inscritos com check-in

- **Algoritmo:** Least Connections (backend com menos conex√µes ativas)- `EventResource` - Recursos necess√°rios (ferramentas, materiais)

- **Health Checks:** Nginx monitora sa√∫de dos backends (30s interval)- `EventPhoto` - Fotos antes/depois dos eventos

- **Failover Autom√°tico:** Se um backend falha, requisi√ß√µes v√£o para os saud√°veis- `EventComment` - Coment√°rios nos eventos

- **Rate Limiting:** 100 req/s por IP na API, 10 req/min no login- `EventReport` - Relat√≥rios de impacto p√≥s-evento



### 2. Processamento Ass√≠ncrono (Distribu√≠do)**Endpoints:**

```

```GET    /api/events/              - Lista eventos

Backend ‚Üí Redis (enfileira) ‚Üí [Worker1 | Worker2] ‚Üí Executa task ‚Üí Salva resultadoPOST   /api/events/              - Cria evento

                                     ‚ÜìGET    /api/events/{id}/         - Detalhes do evento

                              (Round-robin autom√°tico)PUT    /api/events/{id}/         - Atualiza evento

```DELETE /api/events/{id}/         - Deleta evento

POST   /api/events/{id}/join/    - Inscrever-se no evento

**Exemplo:** Enviar email de boas-vindas ap√≥s registroPOST   /api/events/{id}/leave/   - Cancelar inscri√ß√£o

POST   /api/events/{id}/check_in/- Fazer check-in

### 3. Tasks Peri√≥dicas (Agendadas)GET    /api/events/{id}/stats/   - Estat√≠sticas do evento

GET    /api/events/my_events/    - Eventos do usu√°rio

```GET    /api/events/nearby/       - Eventos pr√≥ximos

Celery Beat ‚Üí Agenda task ‚Üí Redis ‚Üí Qualquer Worker dispon√≠vel ‚Üí ExecutaGET    /api/events/categories/   - Lista categorias

``````



**Exemplo:** Limpeza de eventos expirados (diariamente √†s 2h)### `users/` - Gest√£o de Usu√°rios



## üöÄ Escalabilidade**Funcionalidades:**

- Registro de usu√°rio

### Horizontal Scaling (Implementado)- Autentica√ß√£o JWT

- Perfil do usu√°rio

‚úÖ **Backend Django:**- Hist√≥rico de participa√ß√£o em eventos

```bash

# Escalar para 5 r√©plicas**Endpoints:**

make scale-backends N=5```

POST /api/token/          - Login (gera access + refresh token)

# Nginx automaticamente distribui carga entre todasPOST /api/token/refresh/  - Renova access token

```POST /api/users/register/ - Registro de novo usu√°rio

GET  /api/users/profile/  - Perfil do usu√°rio autenticado

‚úÖ **Celery Workers:**```

```bash

# Escalar para 4 workers## ‚ö° Celery - Processamento Ass√≠ncrono

make scale-workers N=4

### Tasks Implementadas

# Tasks s√£o distribu√≠das entre todos os workers

```#### 1. **Email Tasks** (`users/tasks.py`)

```python

### Capacidade Estimada@shared_task

def send_welcome_email(user_id):

**Setup atual (3 backends + 2 workers):**    """Envia email de boas-vindas ap√≥s registro"""

- HTTP: ~12 requisi√ß√µes simult√¢neas (3 √ó 4 Gunicorn workers)```

- Tasks ass√≠ncronas: ~8 tasks simult√¢neas (2 √ó 4 concurrency)

- PostgreSQL: ~100 conex√µes simult√¢neas (default)#### 2. **Event Tasks** (`events/tasks.py`)

```python

**Setup escalado (5 backends + 4 workers):**@shared_task

- HTTP: ~20 requisi√ß√µes simult√¢neas (5 √ó 4 Gunicorn workers)def cleanup_expired_events():

- Tasks ass√≠ncronas: ~16 tasks simult√¢neas (4 √ó 4 concurrency)    """Remove eventos expirados (scheduled: diariamente √†s 2h)"""

- PostgreSQL: Mesmo limite (shared)

@shared_task

### Limites e Otimiza√ß√µesdef generate_monthly_impact_report():

    """Gera relat√≥rio mensal de impacto (scheduled: 1¬∫ dia √†s 3h)"""

**Limita√ß√µes Atuais:**```

- ‚ùå PostgreSQL √© single-point-of-failure (sem replica√ß√£o)

- ‚ùå Redis n√£o tem failover (sem Sentinel/Cluster)### Configura√ß√£o do Celery Beat

- ‚ùå Nginx √© single instance (sem HA)

```python

**Otimiza√ß√µes Futuras:**CELERY_BEAT_SCHEDULE = {

- üîÑ PostgreSQL com replica√ß√£o master-slave    'cleanup-expired-events': {

- üîÑ Redis Sentinel para high availability        'task': 'events.tasks.cleanup_expired_events',

- üîÑ M√∫ltiplas inst√¢ncias do Nginx com Keepalived        'schedule': crontab(hour=2, minute=0),  # Diariamente √†s 2h

- üîÑ Monitoramento com Prometheus + Grafana    },

    'generate-monthly-report': {

## üéØ Apps Django (M√≥dulos)        'task': 'events.tasks.generate_monthly_impact_report',

        'schedule': crontab(day_of_month=1, hour=3, minute=0),  # 1¬∫ do m√™s √†s 3h

### `events/` - Gest√£o de Eventos    },

}

**Models:**```

- `EventCategory` - Categorias (Limpeza, Plantio, Monitoramento, Educa√ß√£o)

- `Event` - Evento principal com localiza√ß√£o, datas, capacidade### Celery Workers

- `EventParticipant` - Participantes inscritos com check-in

- `EventResource` - Recursos necess√°rios (ferramentas, materiais)- **Concorr√™ncia:** 2 workers simult√¢neos

- `EventPhoto` - Fotos antes/depois dos eventos- **Broker:** Redis

- `EventComment` - Coment√°rios nos eventos- **Result Backend:** Redis

- `EventReport` - Relat√≥rios de impacto p√≥s-evento- **Serializa√ß√£o:** JSON



**Endpoints (Load Balanced):**## üîí Seguran√ßa e Autentica√ß√£o

```

GET    /api/events/              - Lista eventos (cache 60s)### JWT Authentication

POST   /api/events/              - Cria evento

GET    /api/events/{id}/         - Detalhes do evento```python

PUT    /api/events/{id}/         - Atualiza evento# Token de acesso: v√°lido por 60 minutos

DELETE /api/events/{id}/         - Deleta evento# Token de refresh: v√°lido por 7 dias

POST   /api/events/{id}/join/    - Inscrever-se no evento# Rota√ß√£o autom√°tica de tokens

POST   /api/events/{id}/leave/   - Cancelar inscri√ß√£o```

POST   /api/events/{id}/check_in/- Fazer check-in

GET    /api/events/{id}/stats/   - Estat√≠sticas do evento**Fluxo:**

GET    /api/events/my_events/    - Eventos do usu√°rio1. Login ‚Üí Gera `access_token` + `refresh_token`

GET    /api/events/nearby/       - Eventos pr√≥ximos2. Requisi√ß√µes autenticadas ‚Üí Header: `Authorization: Bearer {access_token}`

GET    /api/events/categories/   - Lista categorias3. Token expirado ‚Üí Usar `refresh_token` para gerar novo `access_token`

```

### Permiss√µes

### `users/` - Gest√£o de Usu√°rios

- **IsAuthenticated** - Requerido para criar eventos, participar, comentar

**Funcionalidades:**- **IsAuthenticatedOrReadOnly** - Listagem p√∫blica, a√ß√µes requerem autentica√ß√£o

- Registro de usu√°rio

- Autentica√ß√£o JWT## üìä Padr√µes e Boas Pr√°ticas

- Perfil do usu√°rio

- Hist√≥rico de participa√ß√£o em eventos### ‚úÖ Implementados



**Endpoints (Load Balanced):**1. **REST API** - Endpoints RESTful seguindo conven√ß√µes

```2. **JWT Stateless Authentication** - Sem sess√µes no servidor

POST /api/token/          - Login (gera access + refresh token)3. **Containeriza√ß√£o** - Docker para todos os componentes

POST /api/token/refresh/  - Renova access token4. **Async Processing** - Celery para opera√ß√µes demoradas

POST /api/users/register/ - Registro de novo usu√°rio5. **Health Checks** - Endpoint `/health/` para monitoramento

GET  /api/users/profile/  - Perfil do usu√°rio autenticado6. **CORS** - Configurado para comunica√ß√£o frontend/backend

```7. **Filtros e Busca** - django-filter para queries complexas

8. **Pagina√ß√£o** - 20 itens por p√°gina por padr√£o

## ‚ö° Celery - Processamento Ass√≠ncrono Distribu√≠do9. **Serializa√ß√£o** - DRF serializers para valida√ß√£o de dados



### Tasks Implementadas### üé® Frontend - Design Patterns



#### 1. **Email Tasks** (`users/tasks.py`)1. **Component-Based** - Componentes React reutiliz√°veis

```python2. **Hooks** - Custom hooks para l√≥gica compartilhada

@shared_task3. **Context API** - `AuthContext` para estado de autentica√ß√£o

def send_welcome_email(user_id):4. **Client-Side Routing** - Next.js App Router

    """Envia email de boas-vindas ap√≥s registro"""5. **API Client** - Classe centralizada para chamadas HTTP

    # Executado por qualquer worker dispon√≠vel6. **Type Safety** - TypeScript em todo frontend

```

## üöÄ Deployment

#### 2. **Event Tasks** (`events/tasks.py`)

```python### Desenvolvimento

@shared_task

def cleanup_expired_events():```bash

    """Remove eventos expirados (scheduled: diariamente √†s 2h)"""# Backend local

cd mutiroes_backend

@shared_taskpython manage.py runserver

def generate_monthly_impact_report():

    """Gera relat√≥rio mensal de impacto (scheduled: 1¬∫ dia √†s 3h)"""# Frontend local

```cd mutiroes-frontend

npm run dev

### Distribui√ß√£o de Tasks

# Docker Compose

**Celery usa Round-Robin autom√°tico:**docker-compose up -d

1. Task entra na fila do Redis```

2. Primeiro worker dispon√≠vel pega a task

3. Worker executa e salva resultado no Redis### Produ√ß√£o (Recomenda√ß√µes)

4. Backend consulta resultado quando necess√°rio

**Backend:**

**Concurrency:**- ‚úÖ Usar Gunicorn (j√° configurado no Dockerfile)

- Worker 1: 4 tasks simult√¢neas- ‚úÖ PostgreSQL em vez de SQLite

- Worker 2: 4 tasks simult√¢neas- ‚úÖ Nginx como reverse proxy

- **Total: 8 tasks simult√¢neas**- ‚úÖ HTTPS/SSL

- ‚úÖ Vari√°veis de ambiente seguras

### Configura√ß√£o do Celery Beat- ‚úÖ `DEBUG=False`



```python**Frontend:**

CELERY_BEAT_SCHEDULE = {- ‚úÖ Build otimizado: `npm run build`

    'cleanup-expired-events': {- ‚úÖ Servir via Nginx ou CDN

        'task': 'events.tasks.cleanup_expired_events',- ‚úÖ Server-Side Rendering (SSR) habilitado

        'schedule': crontab(hour=2, minute=0),  # Diariamente √†s 2h

    },**Infraestrutura:**

    'generate-monthly-report': {- ‚úÖ Redis persistente

        'task': 'events.tasks.generate_monthly_impact_report',- ‚úÖ Backup autom√°tico do banco

        'schedule': crontab(day_of_month=1, hour=3, minute=0),  # 1¬∫ do m√™s √†s 3h- ‚úÖ Monitoramento (logs, m√©tricas)

    },- ‚úÖ Auto-scaling do Celery workers

}

```## üìà Escalabilidade



## üîí Seguran√ßa### Limita√ß√µes Atuais (Monolito)



### Load Balancer (Nginx)- ‚ùå Backend √© single-point-of-failure

- ‚ùå N√£o h√° load balancing

**Rate Limiting:**- ‚ùå N√£o h√° replica√ß√£o de database

```nginx- ‚ùå Redis n√£o tem failover

# API Endpoints

limit_req zone=api_limit rate=100r/s burst=50;### Como Escalar (Futuro)



# Auth Endpoints (mais restrito)**Horizontal Scaling:**

limit_req zone=auth_limit rate=10r/m burst=10;1. Adicionar m√∫ltiplas inst√¢ncias do backend

```2. Nginx como load balancer

3. PostgreSQL com replica√ß√£o master-slave

**Connection Limiting:**4. Redis Sentinel para high availability

```nginx

limit_conn addr 50;  # M√°ximo 50 conex√µes por IP**Vertical Scaling:**

```1. Aumentar recursos dos containers

2. Otimizar queries do banco

**Security Headers:**3. Adicionar √≠ndices apropriados

```nginx4. Cache agressivo com Redis

X-Frame-Options: SAMEORIGIN

X-Content-Type-Options: nosniff## üîç Monitoramento

X-XSS-Protection: 1; mode=block

```### Health Checks



### JWT Authentication```bash

# Backend health

```pythoncurl http://localhost:8000/health/

# Token de acesso: v√°lido por 60 minutos

# Token de refresh: v√°lido por 7 dias# Readiness (banco + redis dispon√≠veis)

# Rota√ß√£o autom√°tica de tokenscurl http://localhost:8000/readiness/

```

# Liveness (processo ativo)

**Fluxo:**curl http://localhost:8000/liveness/

1. Login ‚Üí Gera `access_token` + `refresh_token````

2. Requisi√ß√µes autenticadas ‚Üí Header: `Authorization: Bearer {access_token}`

3. Token expirado ‚Üí Usar `refresh_token` para gerar novo `access_token`### Logs



### Database Security```bash

# Backend

- **Connection Pooling:** M√°ximo 100 conex√µes compartilhadasdocker-compose logs -f backend

- **Health Checks:** Valida√ß√£o de conex√£o antes de usar

- **Credentials:** Vari√°veis de ambiente (nunca hardcoded)# Celery Worker

docker-compose logs -f celery-worker

## üîç Monitoramento

# Celery Beat

### Health Checksdocker-compose logs -f celery-beat



```bash# Redis

# Sistema completo via load balancerdocker-compose logs -f redis

curl http://localhost/health```



# Backend health (load balanced)## üîß Resili√™ncia

curl http://localhost/api/health/

### Patterns Implementados

# Readiness (banco + redis dispon√≠veis)

curl http://localhost/api/readiness/**Circuit Breaker** (`mutiroes_backend/resilience.py`)

```python

# Liveness (processo ativo)# Prote√ß√£o para chamadas externas

curl http://localhost/api/liveness/# Estados: Closed ‚Üí Open ‚Üí Half-Open

# Falhas m√°ximas: 5

# Check de cada replica individualmente# Timeout de reset: 60s

docker inspect mutiroes-backend1 --format='{{.State.Health.Status}}'```

docker inspect mutiroes-backend2 --format='{{.State.Health.Status}}'

docker inspect mutiroes-backend3 --format='{{.State.Health.Status}}'**Retry com Exponential Backoff**

``````python

# M√°ximo de tentativas: 3

### Logs Distribu√≠dos# Backoff: 1s, 2s, 4s, 8s, ...

# Timeout m√°ximo: 10s

```bash```

# Todos os backends

make logs-backend### Restart Policies



# Backend espec√≠ficoTodos os containers t√™m `restart: unless-stopped`:

docker-compose logs -f backend1- Reiniciam automaticamente em caso de falha

- Iniciam automaticamente ap√≥s reboot do sistema

# Celery workers

make logs-celery## üìö Refer√™ncias



# Nginx (load balancer)- [Django Documentation](https://docs.djangoproject.com/)

make logs-nginx- [Django REST Framework](https://www.django-rest-framework.org/)

- [Celery Documentation](https://docs.celeryproject.org/)

# Todos os servi√ßos- [Next.js Documentation](https://nextjs.org/docs)

make logs-all- [Docker Compose](https://docs.docker.com/compose/)

```

---

### M√©tricas

**Conclus√£o:** Este √© um sistema **monol√≠tico bem estruturado** com processamento ass√≠ncrono, n√£o um sistema distribu√≠do. √â adequado para aplica√ß√µes de pequeno a m√©dio porte e pode ser escalado verticalmente ou evolu√≠do para microservi√ßos no futuro se necess√°rio.

```bash

# Status de todos os containers### 1. Processamento Ass√≠ncrono (Celery)

make status

**Tasks Implementadas:**

# Health check completo- `send_event_notification_email`: Envio de emails de notifica√ß√£o de eventos

make health- `send_bulk_event_reminders`: Envio em massa de lembretes de eventos

- `process_event_report_statistics`: Processamento de estat√≠sticas de relat√≥rios

# Estat√≠sticas do Celery- `generate_monthly_impact_report`: Gera√ß√£o de relat√≥rio mensal de impacto ambiental

make celery-status- `cleanup_expired_events`: Limpeza autom√°tica de eventos expirados

- `update_user_statistics`: Atualiza√ß√£o de estat√≠sticas de usu√°rio

# Uso de recursos- `check_and_award_badges`: Verifica√ß√£o e atribui√ß√£o autom√°tica de badges

make info

```**Celery Beat - Tarefas Peri√≥dicas:**

- Limpeza de eventos expirados: diariamente √†s 2h

## üîß Resili√™ncia- Relat√≥rio mensal: primeiro dia do m√™s √†s 3h



### Load Balancer Resilience**Workers:**

- 2 workers Celery para processamento paralelo

**Nginx Health Checks:**- 1 Celery Beat para agendamento de tarefas

```nginx

server backend1:8000 max_fails=3 fail_timeout=30s;### 2. API Gateway (Nginx)

```

- Se backend falha 3 vezes em 30s, √© marcado como unhealthy**Funcionalidades:**

- Requisi√ß√µes s√£o redirecionadas para backends saud√°veis- **Load Balancing:** Distribui√ß√£o de carga entre 3 inst√¢ncias do backend usando algoritmo `least_conn`

- Backend √© reativado automaticamente quando volta- **Rate Limiting:** 

  - API: 10 requisi√ß√µes/segundo por IP

**Automatic Retry:**  - Auth: 5 requisi√ß√µes/minuto por IP

```nginx- **Connection Limiting:** M√°ximo de 10 conex√µes simult√¢neas por IP

proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;- **Cache:** Cache de arquivos est√°ticos e media com Redis

proxy_next_upstream_tries 3;- **Health Checks:** Monitoramento autom√°tico de sa√∫de dos servi√ßos

```- **CORS:** Configura√ß√£o de headers CORS

- Se backend1 falha, tenta backend2- **Security Headers:** X-Frame-Options, X-Content-Type-Options, X-XSS-Protection

- At√© 3 tentativas em backends diferentes

**Endpoints:**

### Circuit Breaker (Implementado)- `/api/*` ‚Üí Backend Django (load balanced)

- `/health` ‚Üí Health check do API Gateway

**Prote√ß√£o para chamadas externas** (`mutiroes_backend/resilience.py`)- `/nginx_status` ‚Üí M√©tricas do Nginx (restrito)

```python

# Estados: Closed ‚Üí Open ‚Üí Half-Open### 3. Service Discovery (Consul)

# Falhas m√°ximas: 5

# Timeout de reset: 60s**Recursos:**

```- Service Registry para todos os servi√ßos

- Health checks autom√°ticos

### Database Resilience- Service mesh capabilities

- UI de monitoramento em http://localhost:8500

**Connection Health Checks:**

```python### 4. Escalabilidade e Replica√ß√£o

DATABASES = {

    'default': {**Backend Django:**

        'conn_max_age': 600,           # Reusa conex√µes por 10min- 3 r√©plicas (backend1, backend2, backend3)

        'conn_health_checks': True,    # Valida antes de usar- Gunicorn com 4 workers cada

    }- Health checks configurados

}- Compartilhamento de media e static files via volumes

```

**Frontend Next.js:**

### Redis Persistence- 2 r√©plicas (frontend1, frontend2)

- Load balancing via Nginx

**RDB + AOF:**- Health checks configurados

```bash

redis-server --appendonly yes --appendfsync everysec --save 60 1000**Database:**

```- PostgreSQL 15 com capacidade de replica√ß√£o

- **AOF (Append Only File):** Log de todas as escritas (fsync a cada 1s)- Volumes persistentes

- **RDB (Snapshot):** Snapshot a cada 60s se houver 1000+ mudan√ßas

- Recupera√ß√£o autom√°tica em restart**Cache/Message Broker:**

- Redis Master-Slave replication

### Restart Policies- Redis Sentinel para failover autom√°tico

- 3 inst√¢ncias: master, slave, sentinel

Todos os containers t√™m `restart: unless-stopped`:

- Reiniciam automaticamente em caso de falha### 5. Resili√™ncia e Fault Tolerance

- Iniciam automaticamente ap√≥s reboot do sistema

- Podem ser parados manualmente sem restart autom√°tico**Circuit Breaker:**

- Prote√ß√£o para chamadas externas

## üöÄ Deployment- Prote√ß√£o para database

- Prote√ß√£o para Redis

### Desenvolvimento- Estados: Closed ‚Üí Open ‚Üí Half-Open



```bash**Retry Patterns:**

# Sistema distribu√≠do completo- Exponential backoff

make quickstart- M√°ximo de 3 tentativas

- Logging de falhas

# Ou passo a passo

make build**Fallback Mechanisms:**

make up- Valores padr√£o em caso de falha

make migrate- Degrada√ß√£o graciosa de funcionalidades

make createsuperuser

make populate### 6. Monitoramento

```

**Flower:** Monitor do Celery em http://localhost:5555

### Produ√ß√£o (Recomenda√ß√µes)**Consul UI:** Service discovery em http://localhost:8500

**Nginx Status:** M√©tricas em http://localhost/nginx_status

**Backend:**

- ‚úÖ DEBUG=False (j√° configurado)## Rodando o Sistema Completo

- ‚úÖ Gunicorn com m√∫ltiplos workers (j√° configurado)

- ‚úÖ PostgreSQL (j√° configurado)### Pr√©-requisitos

- ‚úÖ HTTPS/SSL via Nginx (adicionar certificado)```bash

- ‚úÖ Secrets em vari√°veis de ambiente seguras- Docker e Docker Compose

- ‚úÖ Firewall e security groups- 4GB RAM m√≠nimo

- 10GB disco dispon√≠vel

**Load Balancer:**```

- ‚úÖ SSL/TLS termination no Nginx

- ‚úÖ Rate limiting agressivo (j√° configurado)### Iniciar Sistema Distribu√≠do

- ‚úÖ Logging estruturado

- ‚úÖ Monitoramento de m√©tricas```bash

# Build e start de todos os servi√ßos

**Database:**docker-compose -f docker-compose.distributed.yml up --build

- ‚úÖ PostgreSQL com replica√ß√£o master-slave

- ‚úÖ Backup autom√°tico di√°rio# Start em background

- ‚úÖ Point-in-time recoverydocker-compose -f docker-compose.distributed.yml up -d

- ‚úÖ Connection pooling (PgBouncer)

# Ver logs

**Infraestrutura:**docker-compose -f docker-compose.distributed.yml logs -f

- ‚úÖ Redis Sentinel para failover

- ‚úÖ Monitoramento com Prometheus + Grafana# Escalar servi√ßos

- ‚úÖ Logs centralizados (ELK Stack)docker-compose -f docker-compose.distributed.yml up --scale backend1=5

- ‚úÖ Auto-scaling com Kubernetes (futuro)

# Parar sistema

## üìä Performancedocker-compose -f docker-compose.distributed.yml down



### Benchmarks Estimados# Parar e limpar volumes

docker-compose -f docker-compose.distributed.yml down -v

**Setup atual (3 backends, 2 workers):**```

- Requisi√ß√µes HTTP simult√¢neas: ~12

- Tasks ass√≠ncronas simult√¢neas: ~8### Acessando os Servi√ßos

- Throughput estimado: ~1000 req/s (com cache)

- Lat√™ncia m√©dia: ~50-100ms (rede local)- **Aplica√ß√£o:** http://localhost

- **API:** http://localhost/api

**Gargalos:**- **Admin Django:** http://localhost/admin

- PostgreSQL (single instance) - resolver com read replicas- **Flower (Celery):** http://localhost:5555

- Redis (single instance) - resolver com Sentinel/Cluster- **Consul UI:** http://localhost:8500

- Nginx (single instance) - resolver com m√∫ltiplas inst√¢ncias + LB- **Health Check:** http://localhost/health



### Cache Strategy### Health Checks



**Nginx Cache:**```bash

- Static files: 1h TTL# Backend health

- Media files: 1 dia TTLcurl http://localhost/health

- API responses: N√£o cacheado (dados din√¢micos)

# Readiness probe

**Redis Cache:**curl http://localhost/readiness

- Sessions: TTL padr√£o do Django

- Celery results: 1h TTL# Liveness probe

- Custom cache: Definido por endpointcurl http://localhost/liveness



## üìö Comandos √öteis# Nginx status

curl http://localhost/nginx_status

```bash```

# Start sistema distribu√≠do

make up## Arquitetura de Rede



# Ver health de tudo```

make healthInternet

   ‚Üì

# Logs de todos os backendsAPI Gateway (Nginx) :80

make logs-backend   ‚Üì

   ‚îú‚îÄ‚Üí Backend 1 :8000 ‚îÄ‚îÄ‚îê

# Escalar backends para 5 r√©plicas   ‚îú‚îÄ‚Üí Backend 2 :8000 ‚îÄ‚îÄ‚îº‚îÄ‚Üí PostgreSQL :5432

make scale-backends N=5   ‚îú‚îÄ‚Üí Backend 3 :8000 ‚îÄ‚îÄ‚îò      ‚Üì

   ‚Üì                         Redis Master :6379

# Escalar workers para 4 r√©plicasFrontend 1 :3000                  ‚Üì

make scale-workers N=4Frontend 2 :3000            Redis Slave :6379

                                  ‚Üì

# Restart de backends sem downtime   Celery Worker 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Redis Sentinel

make restart-backends   Celery Worker 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí

   Celery Beat ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí

# Backup do PostgreSQL                                  ‚Üì

make backup-db                            Consul :8500

```

# Status de todos os servi√ßos

make status## Caracter√≠sticas de Sistema Distribu√≠do



# Informa√ß√µes detalhadas‚úÖ **Processamento Ass√≠ncrono:** Celery com tasks para opera√ß√µes demoradas

make info‚úÖ **API Gateway:** Nginx com load balancing e rate limiting

```‚úÖ **Service Discovery:** Consul para registro e descoberta de servi√ßos

‚úÖ **Escalabilidade Horizontal:** M√∫ltiplas r√©plicas de backend e frontend

## üéØ Caracter√≠sticas de Sistema Distribu√≠do‚úÖ **Load Balancing:** Distribui√ß√£o autom√°tica de carga

‚úÖ **High Availability:** Redis Sentinel para failover

‚úÖ **Load Balancing** - Nginx distribui requisi√ß√µes entre 3 backends  ‚úÖ **Database Replication:** PostgreSQL com suporte a replica√ß√£o

‚úÖ **Horizontal Scaling** - Escalar backends e workers sob demanda  ‚úÖ **Circuit Breaker:** Prote√ß√£o contra falhas em cascata

‚úÖ **Shared Database** - PostgreSQL compartilhado entre todas as r√©plicas  ‚úÖ **Retry Patterns:** Reten√ß√£o autom√°tica com exponential backoff

‚úÖ **Distributed Tasks** - Celery workers processam tasks em paralelo  ‚úÖ **Health Checks:** Monitoramento cont√≠nuo de sa√∫de dos servi√ßos

‚úÖ **Health Checks** - Monitoramento autom√°tico de sa√∫de dos servi√ßos  ‚úÖ **Caching:** Cache distribu√≠do com Redis

‚úÖ **Automatic Failover** - Nginx redireciona se backend falha  ‚úÖ **Logging:** Logs centralizados

‚úÖ **Persistent Storage** - PostgreSQL + Redis com persist√™ncia  ‚úÖ **Monitoring:** Flower para Celery, Consul UI para servi√ßos

‚úÖ **Shared Volumes** - Media/static compartilhados entre backends  

‚úÖ **Circuit Breaker** - Prote√ß√£o contra falhas em cascata  ## Pr√≥ximos Passos

‚úÖ **Rate Limiting** - Prote√ß√£o contra DDoS  

‚úÖ **Connection Pooling** - Reuso eficiente de conex√µes  - [ ] Adicionar Prometheus + Grafana para m√©tricas

‚úÖ **Restart Policies** - Auto-recovery em falhas  - [ ] Implementar ELK Stack para logs centralizados

- [ ] Adicionar Kubernetes manifests

## üìà Pr√≥ximos Passos para Produ√ß√£o- [ ] Implementar service mesh com Istio

- [ ] Adicionar OpenTelemetry para tracing distribu√≠do

- [ ] PostgreSQL Master-Slave Replication
- [ ] Redis Sentinel (3 nodes)
- [ ] Nginx HA com Keepalived (2+ instances)
- [ ] Prometheus + Grafana para m√©tricas
- [ ] ELK Stack para logs centralizados
- [ ] Kubernetes manifests (quando escala > 10 backends)
- [ ] Service Mesh (Istio/Linkerd) para observabilidade
- [ ] OpenTelemetry para distributed tracing
- [ ] CDN para static/media files
- [ ] Auto-scaling baseado em m√©tricas

---

**Conclus√£o:** Este √© um **sistema distribu√≠do real** com load balancing, m√∫ltiplas r√©plicas, escalabilidade horizontal e processamento ass√≠ncrono distribu√≠do. Adequado para aplica√ß√µes de m√©dio a grande porte com alta disponibilidade e capacidade de escalar conforme a demanda.
